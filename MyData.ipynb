{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFV92q_GyTSW",
        "outputId": "d4a37476-4901-4f0a-96fc-8f5f604d3c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/MyDrive/direct_accesses/Final_IA_version_gpt'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbMwAt6dVYcA",
        "outputId": "afbc48e1-ed24-4e59-9906-6fee31778deb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/direct_accesses/Final_IA_version_gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!pip install chess\n",
        "!pip install cairosvg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsqehHc_WAtt",
        "outputId": "1d69084b-a4e1-4c55-feaa-cf6b1065e67b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/direct_accesses/Final_IA_version_gpt\n",
            "Requirement already satisfied: chess in /usr/local/lib/python3.11/dist-packages (1.11.2)\n",
            "Requirement already satisfied: cairosvg in /usr/local/lib/python3.11/dist-packages (2.8.2)\n",
            "Requirement already satisfied: cairocffi in /usr/local/lib/python3.11/dist-packages (from cairosvg) (1.7.1)\n",
            "Requirement already satisfied: cssselect2 in /usr/local/lib/python3.11/dist-packages (from cairosvg) (0.8.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from cairosvg) (0.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from cairosvg) (11.2.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.11/dist-packages (from cairosvg) (1.4.0)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from cairocffi->cairosvg) (1.17.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from cssselect2->cairosvg) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import chess.svg\n",
        "\n",
        "import numpy as np\n",
        "import time, random\n",
        "\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "import cairosvg"
      ],
      "metadata": {
        "id": "t0Cby51-Xx7v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FenDataset(Dataset):\n",
        "    def __init__(self, filenames, has_header=True):\n",
        "        self.all_data = []\n",
        "        self.all_fen = []\n",
        "        for idx, filename in enumerate(filenames):\n",
        "            with open(filename, 'r') as f:\n",
        "                lines = f.readlines()[1:] if has_header else f.readlines()\n",
        "                for line in tqdm(lines, desc='Loading '+filename+' ('+str(idx+1)+'/'+str(len(filenames))+')'):\n",
        "                    fen, move = line[:-1].split(',')\n",
        "                    self.all_fen.append((fen, move))\n",
        "\n",
        "                    board = chess.Board(fen)\n",
        "                    x = create_input(board)\n",
        "                    move = chess.Move.from_uci(move)\n",
        "                    pos = move.from_square*64+move.to_square\n",
        "                    self.all_data.append((x, pos, line[:-1]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.all_data[idx]\n",
        "\n",
        "    def getFen(self, idx):\n",
        "        return self.all_fen[idx]\n",
        "\n",
        "\n",
        "##Modificado:\n",
        "bit_layers = 25  # 1 for turn + 6 white pieces + 6 black pieces + 6 white attacks + 6 black attacks\n",
        "\n",
        "def create_input(board):\n",
        "    # 1. Turn plane (1.0 if white to move, 0.0 if black)\n",
        "    turn_plane = [1.0] * 64 if board.turn == chess.WHITE else [0.0] * 64\n",
        "    posbits = turn_plane\n",
        "\n",
        "    # 2. Piece positions (6 planes for white pieces)\n",
        "    for piece in [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]:\n",
        "        posbits += board.pieces(piece, chess.WHITE).tolist()\n",
        "\n",
        "    # 3. Piece positions (6 planes for black pieces)\n",
        "    for piece in [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]:\n",
        "        posbits += board.pieces(piece, chess.BLACK).tolist()\n",
        "\n",
        "    # 4. Attack maps (6 planes for white attacks)\n",
        "    to_sqs = [chess.SquareSet() for _ in range(7)]\n",
        "    for i, p in board.piece_map().items():\n",
        "        if p.color == board.turn:\n",
        "            to_sqs[p.piece_type] = to_sqs[p.piece_type].union(board.attacks(i))\n",
        "    for i in range(1, 7):\n",
        "        posbits += to_sqs[i].tolist()\n",
        "\n",
        "    # 5. Attack maps (6 planes for black attacks)\n",
        "    board.turn = not board.turn\n",
        "    to_sqs = [chess.SquareSet() for _ in range(7)]\n",
        "    for i, p in board.piece_map().items():\n",
        "        if p.color == board.turn:\n",
        "            to_sqs[p.piece_type] = to_sqs[p.piece_type].union(board.attacks(i))\n",
        "    for i in range(1, 7):\n",
        "        posbits += to_sqs[i].tolist()\n",
        "    board.turn = not board.turn  # restore original turn\n",
        "\n",
        "    # Convert to tensor\n",
        "    x = T.tensor(posbits, dtype=T.float32)\n",
        "    x = x.reshape([bit_layers, 8, 8])\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "nXmO3a_PXwnO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpEBb6H9YJSI",
        "outputId": "952f57ad-0cb6-405d-9893-6e9b4a4ad56e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jugadas  Mi_Pipeline.ipynb  MyData.ipynb  predictions.csv  train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datafiles = ['train.csv']\n",
        "dataset = FenDataset(datafiles)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = T.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "print('Samples:',len(dataset), 'Total,', len(train_dataset),'Train,', len(test_dataset),'Test.')\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfyA1TsLX_o7",
        "outputId": "ff2387b9-00e8-4d13-e43a-dc4a6a14ad83"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading train.csv (1/1): 100%|██████████| 25000/25000 [00:21<00:00, 1150.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: 25000 Total, 20000 Train, 5000 Test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18qT6icRlmi1",
        "outputId": "81d9a1c9-7bd4-4f62-9587-7079afc84393"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/direct_accesses/Final_IA_version_gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"jugadas\", exist_ok=True)\n",
        "patience = 0\n",
        "\n",
        "#a,b, line = dataset[np.random.choice(100)]\n",
        "#fen, best_move = line.split(',')\n",
        "#fen, best_move\n",
        "\n",
        "#board = chess.Board(fen)\n",
        "#board\n",
        "\n",
        "for _, _, line in dataset[0:100]:\n",
        "    fen, best_move = line.strip().split(',')\n",
        "    board = chess.Board(fen)\n",
        "    boardsvg = chess.svg.board(board=board)\n",
        "    cairosvg.svg2png(bytestring=boardsvg.encode('utf-8'), write_to=f\"jugadas/{best_move}.png\")"
      ],
      "metadata": {
        "id": "eg4u243cX6y6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import base64\n",
        "import csv\n",
        "\n",
        "client = OpenAI(api_key=\"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\")\n",
        "\n",
        "image_folder = \"jugadas\"\n",
        "results = []\n",
        "\n",
        "# List all PNG images\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith(\".png\")]\n",
        "\n",
        "def encode_image_to_base64(image_path):\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "for image_file in image_files:\n",
        "    true_label = os.path.splitext(image_file)[0]\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "\n",
        "    try:\n",
        "        base64_image = encode_image_to_base64(image_path)\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"Act as a chess referee: given a top-down 8×8 board image (files a–h left-to-right, ranks 1–8 bottom-to-top), list every piece with its coordinate, then determine white’s forced mate-in-one. Reply with exactly four characters—origin square followed by destination square (e.g., a1a8)—all lowercase, no quotes, no explanation: UCI format (e.g., e2e4, g1f3, etc.).\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": \"What is the best move in this position for white? (Reply with exactly four characters—origin square followed by destination square (e.g., a1a8)—all lowercase, no quotes, no explanation)\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": f\"data:image/png;base64,{base64_image}\"\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=10  # enough for a move like \"e2e4\"\n",
        "        )\n",
        "\n",
        "        predicted_label = response.choices[0].message.content.strip()\n",
        "        results.append((true_label, predicted_label))\n",
        "        print(f\"{true_label} → {predicted_label}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {true_label}: {e}\")\n",
        "        results.append((true_label, \"error\"))\n",
        "\n",
        "# Save to CSV\n",
        "with open(\"predictions.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"True Label\", \"Predicted Label\"])\n",
        "    writer.writerows(results)\n",
        "\n",
        "print(\"Saved predictions to predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNmWSmSagKKg",
        "outputId": "79178ccb-01d4-4050-fe6f-a558b6d2c893"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c6f6 → g8f6\n",
            "f1h1 → f1h1\n",
            "h8g6 → g2g4\n",
            "g3g7 → Qg3g7\n",
            "c7f7 → f1c4\n",
            "f7f8q → f7f8\n",
            "b5b6 → b5b6\n",
            "f4e6 → c8e8\n",
            "h4g6 → c7g7\n",
            "d6d8 → d6d8\n",
            "b8c8 → b8c8\n",
            "g1h2 → a6a7\n",
            "b6e6 → c7e6\n",
            "b3a4 → f6e6\n",
            "b7d7 → b7d7\n",
            "f2h2 → g8h8\n",
            "f4h6 → d1h1\n",
            "h5h7 → d5d6\n",
            "g5f7 → d6c6\n",
            "b7b8q → b7b8\n",
            "d5d1 → c2d1\n",
            "a1a8 → c4a8\n",
            "f2a2 → b3a3\n",
            "d4d5 → a1e5\n",
            "d5f6 → c2d3\n",
            "d6d1 → d6d1\n",
            "g8f7 → f1f2\n",
            "g5h5 → g5h5\n",
            "e5h8 → e5h8\n",
            "c3b5 → c1a3\n",
            "b7b8 → b7b8\n",
            "d8d7 → d8d7\n",
            "e6e8 → e6e8\n",
            "a5h5 → e7e8\n",
            "d2a5 → c6a8\n",
            "c1h6 → c1h6\n",
            "d4d6 → d4d5\n",
            "d5d3 → f2f3\n",
            "g7f7 → g7f7\n",
            "c1a1 → f4d2\n",
            "h8a8 → d6c7\n",
            "a6c8 → c6c8\n",
            "g6f7 → g6f7\n",
            "c6c8 → rh7e7\n",
            "b6f2 → b6f2\n",
            "h8b2 → h8b2\n",
            "a4e4 → d7d1\n",
            "e4g6 → bg6g7\n",
            "e4g4 → h1h4\n",
            "c6e5 → c6b4\n",
            "b3d3 → e6e7\n",
            "d3g6 → h4h5\n",
            "e5e6 → c5c6\n",
            "f4e3 → c5e5\n",
            "c5c8 → c5c8\n",
            "d1d8 → d1d8\n",
            "h3h1 → c6e4\n",
            "c1b2 → d1b2\n",
            "f3h5 → d1h5\n",
            "d7g7 → d7g7\n",
            "h8h5 → a6f6\n",
            "f8e8 → d1g4\n",
            "e5c7 → e5e6\n",
            "h4h5 → qh5f7\n",
            "g3e5 → d4e5\n",
            "f8f2 → g7g3\n",
            "a7a8 → d5a8\n",
            "e1a1 → e1a1\n",
            "h6h7 → h6g7\n",
            "a3a8 → c6a8\n",
            "a4a8 → a4a7\n",
            "e1b4 → g7g8\n",
            "c7c8 → d6e7\n",
            "g4g6 → g4g6\n",
            "g7g8 → d6d8\n",
            "g4h5 → b5d7\n",
            "a5d8 → f6f7\n",
            "h1h2 → h1h2\n",
            "b5c7 → e2e3\n",
            "c2c8 → c2c8\n",
            "a8d8 → d5c6\n",
            "a7d7 → d4d5\n",
            "f5f8 → b6a7\n",
            "b1c3 → e7d7\n",
            "d7f5 → e1f2\n",
            "f3b3 → d2d3\n",
            "b5b8 → g5g6\n",
            "a2a8 → g1g6\n",
            "Saved predictions to predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with open(\"predictions.csv\", \"r\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)  # Skip header\n",
        "\n",
        "    for row in reader:\n",
        "        true_label, predicted_label = row\n",
        "        if predicted_label.lower().strip() == true_label.lower().strip():\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "accuracy = (correct / total) * 100 if total > 0 else 0\n",
        "print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKl6JCorIVcE",
        "outputId": "36bf21c6-18b3-4a9d-9267-8a3d282670a8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 26.14% (23/88)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "yTGrwwCUVLll",
        "outputId": "50046ede-24d5-4bca-fb2c-b6401467f378"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-19-74a7c7c291b7>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-74a7c7c291b7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    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\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWfjN9sKPbaA",
        "outputId": "8dde04ed-e9d9-468e-f20f-cccda685ce70"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import Levenshtein\n",
        "import numpy as np\n",
        "\n",
        "distances = []\n",
        "exact_matches = 0\n",
        "total = 0\n",
        "\n",
        "with open(\"predictions.csv\", \"r\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        true_label, predicted_label = row\n",
        "        true_label = true_label.strip().lower()\n",
        "        predicted_label = predicted_label.strip().lower()\n",
        "\n",
        "        if predicted_label == true_label:\n",
        "            exact_matches += 1\n",
        "\n",
        "        distance = Levenshtein.distance(true_label, predicted_label)\n",
        "        distances.append(distance)\n",
        "        total += 1\n",
        "\n",
        "# Convert to NumPy array for easy stats\n",
        "distances_np = np.array(distances)\n",
        "\n",
        "avg_distance = distances_np.mean()\n",
        "min_distance = distances_np.min()\n",
        "max_distance = distances_np.max()\n",
        "q1 = np.percentile(distances_np, 25)\n",
        "q2 = np.percentile(distances_np, 50)  # median\n",
        "q3 = np.percentile(distances_np, 75)\n",
        "\n",
        "# Print summary\n",
        "print(f\"Total samples: {total}\")\n",
        "print(f\"Exact matches: {exact_matches} ({100 * exact_matches / total:.2f}%)\")\n",
        "print(f\"Average Levenshtein distance: {avg_distance:.2f}\")\n",
        "print(f\"Min distance: {min_distance}\")\n",
        "print(f\"Q1, Q2, Q3: {q1}, {q2}, {q3}\")\n",
        "print(f\"Max distance: {max_distance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g3RfRaxPqe1",
        "outputId": "98ed5d10-9dcd-4b7a-a13d-026028dd1387"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 88\n",
            "Exact matches: 23 (26.14%)\n",
            "Average Levenshtein distance: 2.23\n",
            "Min distance: 0\n",
            "Q1, Q2, Q3: 0.0, 3.0, 4.0\n",
            "Max distance: 5\n"
          ]
        }
      ]
    }
  ]
}